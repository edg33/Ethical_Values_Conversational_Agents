# Understanding Ethical Values Through Surveys and Conversational Agents

This repository presents a study exploring the ability of conversational AI—specifically a custom GPT-4o-powered chatbot—to infer users’ ethical values through naturalistic conversation. The study compares chatbot-inferred ethical classifications with results from a validated psychometric tool, the Ethical Position Questionnaire-5 (EPQ-5).

## Overview

As large language models (LLMs) are increasingly used in sensitive domains like education, healthcare, and ethics training, there is growing interest in their potential to personalize interactions based on user values. This study evaluates whether a chatbot can accurately classify a user's ethical style (e.g., Absolutist, Situationist, Exceptionist, Subjectivist) through scenario-based dialogue, and how this compares to results from the EPQ-5.

## Study Design

- **Participants** completed the EPQ-5 and engaged in a conversation with a GPT-4o-based chatbot trained to infer ethical traits through moral dilemmas.
- The chatbot classified each participant’s ethical style based on dialogue and then revealed its interpretation.
- Participants reflected on both results through a post-study survey.

## Key Findings

- **Accuracy & Agreement**: Only 1/3 of classifications matched exactly, but **87% of participants agreed** with the chatbot's assessment. Two-thirds preferred the chatbot's results to the EPQ-5.
- **Ethical Reflection**: The chatbot stimulated deeper reflection than the traditional survey format.
- **Usefulness**: Participants saw value in using such systems for ethics training, professional development, and even inferring other personal traits like political or health values.
- **Limitations**: Scenario diversity, interaction depth, and platform fragmentation were identified as areas for improvement.

## Contributions

- Demonstrates feasibility of using LLMs for **value-sensitive psychological inference**.
- Highlights **user-perceived accuracy and depth** of AI-driven ethical profiling.
- Offers insights into the design of more **interpretable and personalized AI systems**.
- Provides foundation for future work in conversational diagnostics, ethics education, and personalized decision support.

## Citation

Gray, E. (2025). *Understanding Ethical Values Through Surveys and Conversational Agents*. Unpublished research paper, Tufts University.
